# -*- coding: utf-8 -*-
"""adocAi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NPIP_8crzdu6puS-yGgvtvX9keKqkaGW
"""

!pip install --quiet --upgrade langchain langchain-community langchain-chroma
!pip install -qU langchain-openai
!pip install --upgrade --quiet  GitPython tiktoken

from git import Repo

repo = Repo.clone_from(
    "https://github.com/xbdxllxhi2/clavis/", to_path="./example_data/test_repo3"
)
branch = repo.head.reference

import getpass
import os

os.environ["OPENAI_API_KEY"] = getpass.getpass()

from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o-mini")

from langchain.schema import Document

def getDummyDoc():
   return [Document(page_content=documentation)]

!pip install -qU langchain-community beautifulsoup4
from langchain_community.document_loaders import GitLoader
from langchain_community.document_loaders.generic import GenericLoader
from langchain_community.document_loaders.parsers import LanguageParser
from langchain_text_splitters import Language
from langchain_community.document_loaders import RecursiveUrlLoader

# loader = RecursiveUrlLoader(
#     "https://python.langchain.com/docs/integrations/document_loaders/recursive_url/",
#     max_depth=1,
#     # use_async=False,
#     # extractor=None,
#     # metadata_extractor=None,
#     # exclude_dirs=(),
#     # timeout=10,
#     # check_response_status=True,
#     # continue_on_failure=True,
#     # prevent_outside=True,
#     # base_url=None
# )

# loader = GitLoader(repo_path="./example_data/test_repo1/", branch=branch,
#                    file_filter=lambda  file_path: file_path.endswith(".java"))

loader = GenericLoader.from_filesystem(
    "./example_data/test_repo3/",
    glob="**/*",
    suffixes=[".java"],
    # exclude=["**/non-utf8-encoding.py"],
    parser=LanguageParser(language=Language.JAVA, parser_threshold=500),
)

import bs4
from langchain import hub
from langchain_chroma import Chroma
from langchain_community.document_loaders import ReadTheDocsLoader
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

# docs = getDummyDoc()

docs = loader.load()

# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
# splits = text_splitter.split_documents(docs)


java_splitter = RecursiveCharacterTextSplitter.from_language(
    language=Language.JAVA, chunk_size=2000, chunk_overlap=200
)
texts = java_splitter.split_documents(docs)

vectorstore = Chroma.from_documents(documents=texts, embedding=OpenAIEmbeddings(disallowed_special=()))

# Retrieve and generate using the relevant snippets of the blog.
retriever = vectorstore.as_retriever(
      search_type="mmr",  # Also test "similarity"
    search_kwargs={"k": 8},
)

prompt = hub.pull("rlm/rag-prompt")


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

rag_chain.invoke("What is the root url of secured endpoints in clavis ?")